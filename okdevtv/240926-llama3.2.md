오늘 라마 3.2 버전이 나왔습니다.
https://ollama.com

| 3.2 | 3.21B 파라미터 | 양자화 Q4_K_M | 2.0G 파일 |
| 3.1 | 8.03B 파라미터 | 양자화 Q4_0 | 4.7G 파일 |
| 3 | 8.03B 파라미터 | 양자화 Q4_0 | 4.7G 파일 |
| 2 | 6.74B 파라미터 | 양자화 Q4_0 | 3.8G 파일 |

일단 인스턴스 만들고, 돌려 보겠습니다.
p3 시리즈는 비싸서, 😅
스팟 인스턴스 신청하겠습니다.
기다리기 쫌 그래서 p3 다음 레벨 인스턴스도 신청
그냥 On-demand 가야할 것 같습니다. ㅠㅠ
시간당 얼마 안합니다. $4 사딸라!

https://okdevtv.com/mib/ollama

절대 zsh 까는 시간 줄이려고 bash로 하는 거 아닙니다. 라고 말하고 싶습니다.

nvidia-smi 명령에 아래 메시지가 나오면 설치할 게 더 있습니다.
```
NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.
```

```sh
sudo dnf install kernel-devel-$(uname -r) kernel-headers-$(uname -r) kernel-modules-extra-$(uname -r) -y
```

1초마다 GPU 상태를 볼 수 있습니다.
```
watch -n 1 nvidia-smi
```

12분 지났으면 4딸라 / 12/60 = 거의 천원 넘음

ㅠㅠ
망했습니다. ㅠㅠ
git clone https://github.com/open-webui/open-webui

`pnpm build` 할 때 추가할 것이 있습니다.
```
pnpm i @codemirror/view @codemirror/state @codemirror/autocomplete @codemirror/commands @codemirror/language @codemirror/lang-python
```

오늘의 제 결론입니다. llama3.2는 `이전보다 가볍고 빨라졌고, 헛소리는 여전하다!`

시청 감사합니다. 
40분 p3.2xlarge에서 현지 특파원 kenu 였습니다.

🙇🏻‍♂️