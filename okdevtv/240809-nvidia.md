ec2에서 NVidia 칩셋을 사용하려고 합니다.
g4dn, p3 계열의 인스턴스가 GPU를 지원합니다.

t2.micro 프리티어의 몇십 몇백배 비쌉니다.

일단 로그인
https://aws.amazon.com
EC2에 들어가서 서울 region을 확인합니다.

이제 인스턴스를 만들어서 ollama를 설치할 것입니다.
그 비싼 llama3.1의 405b를 도전해 보겠습니다.
메모리는 200기가 넘게 있어야 동작합니다.

p3.8xlarge가 시간당 $16 정도네요. 한시간에 2만원정도
244G RAM

p3.8xlarge로 진행해 보겠습니다.
g4dn과 다르게 스토리지는 싱글입니다.
스토리지(볼륨)
1개의 볼륨 – 8GiB
300GiB로 해야 405b를 다운받을 수 있습니다. 230기가정도

`인스턴스 시작` 누르면 과금이 시작됩니다. $16 한 시간

https://okdevtv.com/mib/ollama 에 설치 스크립트 있습니다.

p3는 mount 시킬 필요가 없어서 넘어갑니다.
dust는 설치합니다.

```sh
wget https://github.com/bootandy/dust/releases/download/v1.0.0/dust-v1.0.0-x86_64-unknown-linux-gnu.tar.gz
tar xvfz dust-v1.0.0-x86_64-unknown-linux-gnu.tar.gz
sudo mv dust-v1.0.0-x86_64-unknown-linux-gnu/dust /usr/local/bin
rm -rf dust-v1.0.0-x86_64-unknown-linux-gnu*
sudo dust /
```

ollama 설치합니다.
그리고 바로 llama3.1 405b 모델 다운 받겠습니다.


~~~
설치하는 동안 잠시 광고있겠습니다.
1. https://www.egovframe.go.kr/home/ntt/nttRead.do?menuNo=74&bbsId=6&nttId=1894
수요일 저녁 9시부터 GitHub 사용 방법부터 오픈 소스 컨트리뷰터 되기 관련 세미나가 있습니다.
2. https://www.contribution.ac/
09/09 ~ 09/22 표준프레임워크 MSA 개발환경과 협업도구(Git) 멘토링(2주) 
09/23 ~ 09/29 MSA 프로젝트 구조 이해 
09/30 ~ 10/06 MSA 프로젝트 클라우드 배포 실습 
10/07 ~ 10/13 프로젝트 코드 리뷰 및 개선점 연구 
10/14 ~ 10/21 Pull Request, 이슈 등 컨트리뷰션 활동 
10/22 ~ 10/25 프로젝트 전체 과정 회고

이렇게 계획이 잡혀있습니다.
많관부 🙇🏻‍♂️
~~~

올라마 첫 설치에는 에러가 납니다.
```
Dependencies resolved.
Nothing to do.
Complete!
modprobe: ERROR: could not insert 'nvidia': Unknown symbol in module, or unknown parameter (see dmesg)
```

다시 돌리면 됩니다.
```
>>> Creating ollama systemd service...
>>> Enabling and starting ollama service...
>>> NVIDIA GPU installed.
```

이제 바로 다운로드 받겠습니다. 231기가입니다.
3.1 기본은 5기가 정도입니다.

일단 jupyter notebook + nginx를 설치하겠습니다.
https://okdevtv.com/mib/jupyter


pulling d46a016c1dcc...  35% ▕█████           ▏  81 GB/231 GB  141 MB/s  17m35s

# 🎉와~ 17분 다운로드 멉니까

침대 축구도 아니고, 231기가 다운 받는데, 속도가 ㅠㅠ
시간당 2만원짜리 인스턴스인데, ㅠㅠ
여튼 갑니다.

8888포트를 사용하는 jupyter-notebook을 실행하겠습니다.

일단 p3 인스턴스에서 처음 보는 에러 메시지이기 때문에 일단 기본 버전으로 가겠습니다.

3.12.4 버전입니다. 

https://github.com/kenu/langchain-ollama
clone 합니다.

# 유튜브 판다스 스튜디오 [바로가기](https://www.youtube.com/channel/UCh-c-LFH9Q6VbHRRqD4oLOA)

### 재생목록: 랭체인 응용하기 실습파일을 공유합니다.
- 랭체인(LangChain) + 올라마(Ollama) 활용 예제

매우 고마운 분의 오픈 소스 입니다.

이제 notebook에서 실행해 보겠습니다. shift+Enter

기본은 gemma 모델이라 이것도 설치하겠습니다.
ollama pull gemma

405b는 거의 다 왔네요
pulling d46a016c1dcc...  93% ▕██████████████  ▏ 214 GB/231 GB   85 MB/s  3m20s

결승점에서 느려지면 stop(Ctrl+C)했다가 다시 실행해도 이어갑니다.

405b를 다운 받았는데, verify 시간도 꽤 걸립니다. #아내돈
```
ollama pull llama3.1:405b
pulling manifest 
```

이제 gemma(점마) 말고, llama(라마)로 실행해 보겠습니다.

세종대왕이 맥을 만들었을 때, 9년 동안 공부했는데, 9라는 숫자가 나타나서 나중에 이 숫자가 세자를 대신하고 있음을 알게 되었다고 한다. 그 이후로 이 숫자는 한국의 과학·문화 발전에 있어 중요한 역할을 하였다고 한다.

> 이게 뭔 개소리야
> https://www.youtube.com/watch?v=DGANAv-1uzw


---
아직도 405b를 다운받아서 230기가 데이터 파일을 검증하고 있습니다. #아내돈 

10분 안에 405b를 사용할 수 있을 것 같지는 않아 보입니다.
1시간에 테스트하기에는 벅찬 모델입니다.
지금 55분지나고 있습니다.
천천히 갈게요

궁금한 것이 있으면 채팅창에 남겨주세요.

프로그래머 말고 먹고 살 수 있는 길이 있나요? 라고 물으신다면 
이성 친구가 필요한데 어떻게 만들 수 있나요? 
저는 잘 하는 게 하나도 없는데, 왜 태어 난 걸까요?
돈을 버는 이유는 뭔가요? 아빠가 재벌인 걸까요? 아니면 엄마가 재벌집?

반에서 1등하려면 어떻게 해야 되나요?



---
드디어 다운로드 다 받아서 검증도 되었습니다.
231G

🎉
테스트 해 보겠습니다.

노답?
새 술은 새 부대에 담으라는 건가요?
30초가 지났지만 노답이네요. 

No Answer, No Response, 405b How big is your thinking? 

일단 ollama + llama 3.1 : 405b 테스트는 실패입니다.
---

오늘은 여기까지입니다.
https://mp4.okdevtv.com 많은 관심 부탁드립니다. 


---
yona는 메모리 4G 이상으로 추천합니다.
scala + play framework 였는데, 이상적인 기술 세트라고 개인적으로 생각합니다. 그냥 java + play framework 였음 좋았을텐데요.
scala (SCAlable LAngauge language라 쉽진 않아요)


---
g4dn 으로 도전해 보려고 합니다.
vCPU 갯수로 안될 수도 있습니다.

install 스크립트는 이 링크에 있습니다.
https://okdevtv.com/mib/ollama


network가 안 좋은 것 같습니다.
작은 인스턴스로 테스트 해 봐야 할 것 같습니다.

g4dn.16xlarge
시간당 5.353 USD








