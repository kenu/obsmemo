google의 gemma2 인스턴스를 테스트해 봤는데, 이런 피드백이 있었습니다.
`존나느려` so slow

그래서 서버의 사양을 좀 높여 보겠습니다.
이전 서버는 8cpu에 32g RAM이었는데 시간당 $0.9 정도 되었습니다.

시작해 보겠습니다.

시간당 $1.5 정도입니다. 2천원 살짝 넘기는 금액이죠.
g4dn.4xlarge
16cpu에 64g 램입니다.

추가 스토리지는 동일하게 200g 정도 됩니다.


ollama 설치 시작합니다.
약 10분 정도 걸립니다.
ollama의 GPU 설치는 다시 시도합니다.

conda 도 같이 설치하겠습니다.
파이썬 버전은 conda가 조정하기 좋아서요.

곧 서버 열립니다.
http://54.180.32.165:8080

gemma2 모델 다운 받겠습니다.
ollama pull gemma2

지금 보시는 분들은 테스트 부탁드립니다.
이메일은 페이크로 해주세요.
kenu.heo@gmail.com / okpass <---- 관리자 계정입니다.

**​​AI 답변이 유용할까요?**

저는 그렇다고 생각합니다. 무플보다 악플
악플보다는 AI플이 더 낫죠.
https://pytorch.kr 커뮤니티와 https://inflearn.com 은 이미 AI 인턴을 사용하고 있습니다.


llama3:70b 를 설치해서 비교해 보겠습니다.
40기가 ㅎㅎㅎ

stuck 된 것 같은데 리붓하겠습니다.
재부팅 뒤에 접속하면 200g 스토리지 붙여야 됩니다.
한 줄이면 됩니다.
`sudo mount /dev/nvme1n1 /data`
이러면 집나간 스토리지 찾아옵니다. ![face-green-smiling](https://yt3.ggpht.com/G061SAfXg2bmG1ZXbJsJzQJpN8qEf_W3f5cb5nwzBYIV58IpPf6H90lElDl85iti3HgoL3o=w48-h48-c-k-nd)![face-green-smiling](https://yt3.ggpht.com/G061SAfXg2bmG1ZXbJsJzQJpN8qEf_W3f5cb5nwzBYIV58IpPf6H90lElDl85iti3HgoL3o=w48-h48-c-k-nd)![face-green-smiling](https://yt3.ggpht.com/G061SAfXg2bmG1ZXbJsJzQJpN8qEf_W3f5cb5nwzBYIV58IpPf6H90lElDl85iti3HgoL3o=w48-h48-c-k-nd)![face-green-smiling](https://yt3.ggpht.com/G061SAfXg2bmG1ZXbJsJzQJpN8qEf_W3f5cb5nwzBYIV58IpPf6H90lElDl85iti3HgoL3o=w48-h48-c-k-nd)

```
/home/ec2-user/miniconda3/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work

  warn("Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work", RuntimeWarning)
```


시청 감사합니다. [https://mp4.okdevtv.com/food](https://www.youtube.com/redirect?event=live_chat&redir_token=QUFFLUhqbHRDNjI5NmI1OTZKYXZNdXA0YzZmUzRFaWtIQXxBQ3Jtc0tsYm56YWR2ZWZ2YXJraWkwTnRoS3JFUllaTFRmUWgxTDVMcE5Wd2ttUm1wa3U3bF82N3FYZDZuX2xsbUUzR1BTeWE5ZHFOVGpEN3lfb2FsZndmdlFsYUU2VE1Ea1hDQlBuNmR5TXUtTjJPMS1fb3FDZw&q=https%3A%2F%2Fmp4.okdevtv.com%2Ffood) 맛저에 도움되기를 바랍니다.
